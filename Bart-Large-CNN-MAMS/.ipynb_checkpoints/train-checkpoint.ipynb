{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0595d6e-ad9e-45ee-8991-887b76b9a876",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "# print(\"Loading tokenizer...\")\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"facebook/bart-large-cnn\")\n",
    "# print(\"Tokenizer loaded.\")\n",
    "\n",
    "# print(\"Loading model...\")\n",
    "# model = AutoModelForSeq2SeqLM.from_pretrained(\"facebook/bart-large-cnn\")\n",
    "# print(\"Model loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5eed7d3-c7d5-4a52-9bea-a2d52b231eff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "723b239d-44f1-4113-b3fc-a62e40da90a7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %cd course-eval/Bart-Large-CNN\n",
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28c2e146-9d3a-4a2b-ac84-f6b574eb4206",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99eeed0e-fdfc-460b-9310-4d9d0739e115",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec4dbd1-8904-455e-989e-117554395824",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.insert(0, '/home/thanapon.nor/course-eval/Bart-Large-CNN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b4955e-b122-4304-a61c-feb6ea211d9d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from seq2seq_model_M import Seq2SeqModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e988ebec-61e7-420f-b8bc-ee5d722e908f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_args = {\n",
    "#     \"reprocess_input_data\": True,\n",
    "#     \"overwrite_output_dir\": True,\n",
    "#     \"max_seq_length\": 50,\n",
    "#     \"train_batch_size\": 16,\n",
    "#     \"num_train_epochs\": 5,\n",
    "#     \"save_eval_checkpoints\": True,\n",
    "#     \"save_model_every_epoch\": True,\n",
    "#     \"evaluate_during_training\": False,\n",
    "#     \"evaluate_generated_text\": False,\n",
    "#     \"evaluate_during_training_verbose\": True,\n",
    "#     \"use_multiprocessing\": False,\n",
    "#     \"max_length\": 150,\n",
    "#     \"manual_seed\": 42,\n",
    "#     # \"gradient_accumulation_steps\": step,\n",
    "#     # \"learning_rate\":  lr,\n",
    "#     \"save_steps\": 99999999999999,\n",
    "# }\n",
    "\n",
    "# model = Seq2SeqModel(\n",
    "#             encoder_decoder_type=\"bart\",\n",
    "#             # encoder_decoder_name=f\"outputs/original/epoch{int(fold)-1}\",\n",
    "#             encoder_decoder_name=\"facebook/bart-large-cnn\",\n",
    "#             args=model_args,\n",
    "#         )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26188bd2-1640-4743-93e8-fdcb2d8f66ca",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "# Training Section\n",
    "## Don't forget to change fold = \"\" and test-dataset path in test.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe21b116-2b0f-40e5-a25d-f4f0ea4daa30",
   "metadata": {},
   "outputs": [],
   "source": [
    "fold = \"3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f1bac9-cb61-49dd-94fc-ab2d716a17b1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_path = f\"../Dataset/original/org-fold{fold}.txt\"\n",
    "model_path = f\"outputs/original/epoch{int(fold)-1}\"\n",
    "\n",
    "with open(train_path, \"r\",encoding='utf-8') as f:\n",
    "    file = f.readlines()\n",
    "train_data = []\n",
    "for line in file:\n",
    "    # print(line)\n",
    "    x, y = line.split(\"\\001\")[0], line.strip().split(\"\\001\")[1]\n",
    "    train_data.append([x, y])\n",
    "    #else:\n",
    "    #    print(f\"Issue with line: {line.strip()}\")\n",
    "# train_data = [\n",
    "#     [\"one\", \"1\"],\n",
    "#     [\"two\", \"2\"],\n",
    "# ]\n",
    "\n",
    "train_df = pd.DataFrame(train_data, columns=[\"input_text\", \"target_text\"])\n",
    "#print(train_df[\"target_text\"])\n",
    "# steps = [1, 2, 3, 4, 6]\n",
    "# learing_rates = [4e-5, 2e-5, 1e-5, 3e-5]\n",
    "steps = [1]\n",
    "learing_rates = [4e-5]\n",
    "\n",
    "\n",
    "print(\"Training Start\")\n",
    "best_accuracy = 0\n",
    "for lr in learing_rates:\n",
    "    print(f\"Current training at fold-{fold}\")\n",
    "    for step in steps:\n",
    "        model_args = {\n",
    "            \"reprocess_input_data\": True,\n",
    "            \"overwrite_output_dir\": True,\n",
    "            \"max_seq_length\": 50,\n",
    "            \"train_batch_size\": 16,\n",
    "            \"num_train_epochs\": 5,\n",
    "            \"save_eval_checkpoints\": True,\n",
    "            \"save_model_every_epoch\": True,\n",
    "            \"evaluate_during_training\": False,\n",
    "            \"evaluate_generated_text\": False,\n",
    "            \"evaluate_during_training_verbose\": True,\n",
    "            \"use_multiprocessing\": False,\n",
    "            \"max_length\": 150,\n",
    "            \"manual_seed\": 42,\n",
    "            \"gradient_accumulation_steps\": step,\n",
    "            \"learning_rate\":  lr,\n",
    "            \"save_steps\": 99999999999999,\n",
    "        }\n",
    "\n",
    "        torch.cuda.empty_cache()  \n",
    "                \n",
    "        # Initialize model\n",
    "        model = Seq2SeqModel(\n",
    "            encoder_decoder_type=\"bart\",\n",
    "            # encoder_decoder_name=model_path,\n",
    "            encoder_decoder_name=\"facebook/bart-large-cnn\",\n",
    "            args=model_args,\n",
    "        )\n",
    "\n",
    "        # print(f\"Model: {model?}\")\n",
    "\n",
    "        # Train the model\n",
    "        best_accuracy = model.train_model(train_df, best_accuracy)\n",
    "print(f\"Model Path: {model_path}\")\n",
    "print(f\"Train dataset: {train_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2fad41f-ce64-453b-b087-c6c78a426a9e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "toc-autonumbering": true,
  "toc-showcode": false,
  "toc-showtags": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
